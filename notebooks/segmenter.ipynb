{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c30fab12-c956-4f84-b196-98b62b7d7db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d90dd4a8-3b3a-4b3d-a5a5-334fd1f5ae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.io import read_image\n",
    "from torchvision.models import resnet50, ResNet50_Weights # Importing specific model\n",
    "from torchvision.models.segmentation import fcn_resnet50, FCN_ResNet50_Weights\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn_v2, FasterRCNN_ResNet50_FPN_V2_Weights\n",
    "from torchvision.models.detection import maskrcnn_resnet50_fpn_v2, MaskRCNN_ResNet50_FPN_V2_Weights\n",
    "from torchvision.utils import draw_bounding_boxes, draw_segmentation_masks\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3662e66e-9789-459d-8248-f2cf187b536a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"savefig.bbox\"] = 'tight'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46f6e3b6-3b88-4a7c-a665-f5674f51b887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 세그멘테이션 및 저장 함수\n",
    "def segment_and_save_image(image_path, save_path):\n",
    "    # 이미지 로드\n",
    "    img = read_image(image_path)\n",
    "    img = img[:3, :, :]\n",
    "\n",
    "    # 모델 초기화\n",
    "    weights = FCN_ResNet50_Weights.DEFAULT\n",
    "    model = fcn_resnet50(weights=weights)\n",
    "    model.eval()\n",
    "\n",
    "    # 전처리\n",
    "    preprocess = weights.transforms()\n",
    "    batch = preprocess(img).unsqueeze(0)\n",
    "\n",
    "    # 예측\n",
    "    prediction = model(batch)[\"out\"]\n",
    "    normalized_masks = prediction.softmax(dim=1)\n",
    "\n",
    "    # 원본 이미지 로드\n",
    "    original_image = to_pil_image(batch[0])\n",
    "\n",
    "    # 클래스 이름과 인덱스 매핑\n",
    "    class_to_idx = {cls: idx for idx, cls in enumerate(weights.meta[\"categories\"])}\n",
    "\n",
    "    # 오버레이 초기화\n",
    "    overlay = np.zeros((original_image.height, original_image.width, 4))\n",
    "\n",
    "    # 마스크 생성 및 적용\n",
    "    for cls_idx in class_to_idx.values():\n",
    "        mask = normalized_masks[0, cls_idx].detach().numpy()\n",
    "        mask = mask > 0.6\n",
    "        color = np.random.rand(3)\n",
    "        overlay[mask] = np.append(color, 0.5)\n",
    "\n",
    "    # 이미지 시각화 및 저장\n",
    "    # plt.imshow(original_image)\n",
    "    plt.imshow(overlay, interpolation='none')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a63efb1-cd75-4365-a39d-ab54df6e46d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 파일을 순회하며 함수 호출\n",
    "base_image_folder = 'streetview'\n",
    "output_folder = 'streetview_assignment'\n",
    "\n",
    "for i in range(1,4):\n",
    "    image_file = f'image0{i}.png'\n",
    "    segment_and_save_image(os.path.join(base_image_folder, image_file),\n",
    "                           os.path.join(output_folder, image_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0fd5dff9-d474-4525-bead-efdcfd21d70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torchvision.transforms.functional import to_tensor\n",
    "\n",
    "def object_detection(image_path, save_path):\n",
    "    # 이미지 로드 및 전처리\n",
    "    img = read_image(image_path)\n",
    "    img = img[:3, :, :]  # RGBA에서 RGB로 변경\n",
    "    img_tensor = img.float() / 255\n",
    "\n",
    "    # 객체 탐지 모델 초기화 및 평가 모드 설정\n",
    "    detection_model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "    detection_model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        predictions = detection_model([img_tensor])\n",
    "\n",
    "    # 원본 이미지 로드\n",
    "    original_image = to_pil_image(img_tensor)\n",
    "\n",
    "    # 객체 탐지 결과 시각화\n",
    "    plt.imshow(original_image)\n",
    "    for prediction in predictions[0]['boxes']:\n",
    "        x1, y1, x2, y2 = prediction.numpy()\n",
    "        plt.gca().add_patch(plt.Rectangle((x1, y1), x2 - x1, y2 - y1, fill=False, edgecolor='red', linewidth=2))\n",
    "\n",
    "    # 이미지 저장\n",
    "    plt.axis('off')\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "599d44fa-0165-4999-acb5-bba40d239989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 파일을 순회하며 함수 호출\n",
    "base_image_folder = r'C:\\Users\\Jasic\\Jupyter\\04AI2\\streetview'\n",
    "output_folder2 = r'streetview_assignment_od'\n",
    "\n",
    "\n",
    "if not os.path.exists(output_folder2):\n",
    "    os.makedirs(output_folder2)\n",
    "\n",
    "for i in range(1,4):\n",
    "    image_file = f'image0{i}.png'\n",
    "    object_detection(os.path.join(base_image_folder, image_file),\n",
    "                           os.path.join(output_folder2, image_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49d2df47-c890-43f9-8dc9-aab018071110",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.detection import maskrcnn_resnet50_fpn\n",
    "\n",
    "def instance_segmentation(image_path, save_path):\n",
    "    # 이미지 로드 및 전처리\n",
    "    img = read_image(image_path)\n",
    "    img = img[:3, :, :]  # RGBA에서 RGB로 변경\n",
    "    img_tensor = img.float()/ 256\n",
    "\n",
    "    # 인스턴스 분할 모델 초기화 및 평가 모드 설정\n",
    "    segmentation_model = maskrcnn_resnet50_fpn(pretrained=True)\n",
    "    segmentation_model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        predictions = segmentation_model([img_tensor])\n",
    "\n",
    "    # 원본 이미지 로드\n",
    "    original_image = to_pil_image(img_tensor)\n",
    "\n",
    "    # 인스턴스 분할 결과 시각화\n",
    "    plt.imshow(original_image)\n",
    "    for element in range(len(predictions[0]['masks'])):\n",
    "        mask = predictions[0]['masks'][element, 0]\n",
    "        mask = mask.mul(255).byte().cpu().numpy()\n",
    "        plt.imshow(mask, alpha=0.5)\n",
    "\n",
    "    # 이미지 저장\n",
    "    plt.axis('off')\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8edf71b9-070a-4585-8151-b5cb38261def",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jasic\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MaskRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=MaskRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\" to C:\\Users\\Jasic/.cache\\torch\\hub\\checkpoints\\maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 170M/170M [00:30<00:00, 5.76MB/s]\n"
     ]
    }
   ],
   "source": [
    "# 이미지 파일을 순회하며 함수 호출\n",
    "base_image_folder = r'C:\\Users\\Jasic\\Jupyter\\04AI2\\streetview'\n",
    "output_folder3 = 'streetview_assignment_is'\n",
    "\n",
    "if not os.path.exists(output_folder3):\n",
    "    os.makedirs(output_folder3)\n",
    "    \n",
    "for i in range(1,4):\n",
    "    image_file = f'image0{i}.png'\n",
    "    instance_segmentation(os.path.join(base_image_folder, image_file),\n",
    "                           os.path.join(output_folder3, image_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131e738b-1d88-4777-9ff9-aa35e5af0f39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
